{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'aerial-cactus-identification/train/'\n",
    "classes = (0,1)\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('aerial-cactus-identification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x139bfe730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['has_cactus'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cactusTrainData(Dataset): \n",
    "    def __init__(self, df, train_path = 'aerial-cactus-identification/train/', transform=None):\n",
    "        self.data = df\n",
    "        self.train_path = train_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.train_path,self.data['id'].values[index])\n",
    "        img = Image.open(img_path)\n",
    "        label = self.data['has_cactus'].values[index].tolist()\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img_tensor = transforms.ToTensor()\n",
    "            img = img_tensor(img) #.requires_grad_()\n",
    "        return img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cactusTestData(Dataset): \n",
    "    def __init__(self, img_path = 'aerial-cactus-identification/test/*', transform=None):\n",
    "        self.img_path = glob.glob(img_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index])\n",
    "        *_, label = self.img_path[index].split('/')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img_tensor = transforms.ToTensor()\n",
    "            img = img_tensor(img) #.requires_grad_()\n",
    "        return img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = cactusTrainData(df_train, transform=train_transformations)\n",
    "testset = cactusTestData(transform=test_transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = train_test_split(trainset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valloader = torch.utils.data.DataLoader(valset, batch_size=4, shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, padding=1)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        self.fc1 = nn.Linear(in_features= 8 * 8 * 24, out_features=10)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=10, out_features=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 8 * 8 * 24)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.289\n",
      "[2,  2000] loss: 0.167\n",
      "[3,  2000] loss: 0.132\n",
      "[4,  2000] loss: 0.129\n",
      "[5,  2000] loss: 0.113\n",
      "[6,  2000] loss: 0.104\n",
      "[7,  2000] loss: 0.102\n",
      "[8,  2000] loss: 0.095\n",
      "[9,  2000] loss: 0.087\n",
      "[10,  2000] loss: 0.086\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        img, label = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(img)\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 98 %\n",
      "Accuracy of     1 : 95 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "with torch.no_grad():\n",
    "    #i=0\n",
    "    for data in valloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \"\"\"if i < 3:\n",
    "            print(outputs)\n",
    "            print(predicted)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\"\"\"\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_sub = []\n",
    "file_sub = []\n",
    "with torch.no_grad():\n",
    "    #i = 0\n",
    "    for data in testloader:\n",
    "        images, file = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \"\"\"if i < 3:\n",
    "            print(outputs)\n",
    "            print(predicted)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\"\"\"\n",
    "        \n",
    "        for jpg, pre in zip(file, predicted.tolist()):\n",
    "            pre_sub.append(pre)\n",
    "            file_sub.append(jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {'id':file_sub,'has_cactus':pre_sub}\n",
    "\n",
    "df_sub = pd.DataFrame(submission_dict)\n",
    "df_sub.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.sort_index(inplace=True)\n",
    "df_compare = pd.read_csv('submission.csv')\n",
    "df_compare.loc[df_compare['has_cactus'] >= 0.5,'has_cactus'] = 1\n",
    "df_compare.loc[df_compare['has_cactus'] < 0.5,'has_cactus'] = 0\n",
    "df_compare.set_index('id', inplace=True)\n",
    "df_compare.sort_index(inplace=True)\n",
    "df_tmp = df_sub == df_compare\n",
    "df_tmp[df_tmp['has_cactus']==False];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.125%\n"
     ]
    }
   ],
   "source": [
    "print(str(100 -len(df_tmp[df_tmp['has_cactus']==False])/len(df_sub)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Neural Network Accuracy, for the test data, is listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cactus_e10.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuNet()\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3, 3, 3])\n",
      "torch.Size([12])\n",
      "torch.Size([24, 12, 3, 3])\n",
      "torch.Size([24])\n",
      "torch.Size([10, 1536])\n",
      "torch.Size([10])\n",
      "torch.Size([2, 10])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for parameter in net.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(trainloader).next()[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(testloader).next()[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "for i in range(15000):\n",
    "    if i % 5000 == 4999:\n",
    "        print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py382] *",
   "language": "python",
   "name": "conda-env-py382-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
